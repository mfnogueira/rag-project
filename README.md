# ğŸ›ï¸ Assistente de SÃºmulas TCEMG

Sistema de RAG (Retrieval-Augmented Generation) para consulta inteligente de sÃºmulas do Tribunal de Contas do Estado de Minas Gerais.

## ğŸ“‹ VisÃ£o Geral

Este projeto implementa um assistente conversacional baseado em IA que permite realizar consultas em linguagem natural sobre sÃºmulas do TCEMG. O sistema utiliza tÃ©cnicas avanÃ§adas de RAG com Self-Query para inferir automaticamente filtros de metadados e realizar buscas semÃ¢nticas precisas.

### âœ¨ Funcionalidades

- ğŸ” **Busca SemÃ¢ntica HÃ­brida**: Vetores densos e esparsos para mÃ¡xima precisÃ£o
- ğŸ¤– **Self-Query Retriever**: ExtraÃ§Ã£o automÃ¡tica de filtros a partir da pergunta
- ğŸ’¬ **Interface Conversacional**: Chat interativo via Streamlit
- ğŸ“Š **Observabilidade Completa**: Rastreamento detalhado com Langfuse
- â˜ï¸ **Cloud-Ready**: Suporte a Qdrant Cloud e local
- ğŸ“š **Processamento AutomÃ¡tico**: ExtraÃ§Ã£o de metadados e chunks dos PDFs

### ğŸ› ï¸ Stack TecnolÃ³gica

| Componente | Tecnologia | PropÃ³sito |
|------------|-----------|-----------|
| **LLM** | OpenAI GPT-4o-mini | GeraÃ§Ã£o de respostas e anÃ¡lise de documentos |
| **Embeddings** | text-embedding-3-large | VetorizaÃ§Ã£o semÃ¢ntica (3072 dimensÃµes) |
| **Vector Store** | Qdrant Cloud | Armazenamento e busca vetorial |
| **OrquestraÃ§Ã£o** | LangGraph | Controle de fluxo e estado |
| **Framework** | LangChain | IntegraÃ§Ã£o LLM + Vector Store |
| **Observabilidade** | Langfuse | Monitoramento e traces |
| **Interface** | Streamlit | Frontend interativo |
| **ExtraÃ§Ã£o PDF** | MarkItDown | Processamento de documentos |
| **Gerenciador** | uv | GestÃ£o de dependÃªncias Python |

---

## ğŸ—ï¸ Arquitetura

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   UsuÃ¡rio   â”‚
â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”˜
       â”‚ Pergunta
       â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚        Streamlit Interface          â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚         LangGraph Workflow           â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â” â”‚
â”‚  â”‚  Retrieve  â”‚â”€â”€â”€â–¶â”‚   Generate   â”‚ â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜ â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
      â–¼                 â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”   â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Qdrant    â”‚   â”‚  OpenAI  â”‚
â”‚   Cloud     â”‚   â”‚   API    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜   â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
      â”‚
      â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  Langfuse   â”‚
â”‚ Monitoring  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

### Fluxo de Dados

1. **Input**: UsuÃ¡rio faz pergunta em linguagem natural
2. **Self-Query**: LLM analisa a pergunta e extrai:
   - Termos semÃ¢nticos para busca
   - Filtros de metadados (status, ano, nÃºmero da sÃºmula)
3. **Retrieval**: Busca hÃ­brida no Qdrant retorna chunks relevantes
4. **Generation**: GPT-4o-mini gera resposta contextualizada
5. **Output**: Resposta + fontes sÃ£o exibidas no chat

---

## ğŸ“ Estrutura do Projeto

```
rag-project/
â”œâ”€â”€ app/
â”‚   â”œâ”€â”€ graph/
â”‚   â”‚   â”œâ”€â”€ rag_graph.py          # OrquestraÃ§Ã£o LangGraph
â”‚   â”‚   â””â”€â”€ prompt.py             # Templates de prompts
â”‚   â”œâ”€â”€ ingest/
â”‚   â”‚   â”œâ”€â”€ embed_qdrant.py       # Cliente Qdrant + Embeddings
â”‚   â”‚   â””â”€â”€ extract_text.py       # Pipeline de ingestÃ£o
â”‚   â”œâ”€â”€ retrieval/
â”‚   â”‚   â”œâ”€â”€ retriever.py          # Self-Query Retriever
â”‚   â”‚   â””â”€â”€ self_query.py         # DefiniÃ§Ã£o de metadados
â”‚   â””â”€â”€ utils/
â”‚       â””â”€â”€ settings.py           # ConfiguraÃ§Ãµes
â”œâ”€â”€ sumulas/                      # PDFs das sÃºmulas (125 arquivos)
â”œâ”€â”€ app.py                        # Interface Streamlit
â”œâ”€â”€ pyproject.toml                # DependÃªncias (uv)
â”œâ”€â”€ .env                          # VariÃ¡veis de ambiente
â””â”€â”€ README.md
```

---

## ğŸš€ InÃ­cio RÃ¡pido

### PrÃ©-requisitos

- **Python 3.12+**
- **uv** (gerenciador de pacotes Python)
- Contas nas plataformas:
  - [OpenAI](https://platform.openai.com/) (API key)
  - [Qdrant Cloud](https://cloud.qdrant.io/) (cluster + API key)
  - [Langfuse](https://cloud.langfuse.com/) (opcional, para observabilidade)

### 1ï¸âƒ£ InstalaÃ§Ã£o do uv

**Linux/macOS/WSL:**
```bash
curl -LsSf https://astral.sh/uv/install.sh | sh
export PATH="$HOME/.local/bin:$PATH"
```

**Windows (PowerShell):**
```powershell
irm https://astral.sh/uv/install.ps1 | iex
```

### 2ï¸âƒ£ Clone e Configure

```bash
git clone https://github.com/mfnogueira/rag-project.git
cd rag-project
```

### 3ï¸âƒ£ Configurar VariÃ¡veis de Ambiente

Crie um arquivo `.env` na raiz do projeto:

```env
# OpenAI
OPENAI_API_KEY=sk-proj-xxxxxxxxxxxxxxxxxx

# Qdrant Cloud
QDRANT_URL=https://seu-cluster.cloud.qdrant.io:6333
QDRANT_API_KEY=sua-api-key-aqui

# Langfuse (opcional)
LANGFUSE_PUBLIC_KEY=pk-lf-xxxxxxxxxx
LANGFUSE_SECRET_KEY=sk-lf-xxxxxxxxxx
LANGFUSE_HOST=https://us.cloud.langfuse.com
```

> **ğŸ’¡ Dica**: Para obter as credenciais do Qdrant Cloud, acesse o [painel](https://cloud.qdrant.io/), crie um cluster gratuito e copie a URL e API Key.

### 4ï¸âƒ£ Instalar DependÃªncias

**Linux/macOS/WSL:**
```bash
uv sync
```

**Windows (se houver erro de permissÃ£o):**
```bash
export UV_LINK_MODE=copy
uv sync
```

### 5ï¸âƒ£ Adicionar Documentos

Coloque os PDFs das sÃºmulas na pasta `sumulas/`.

> ğŸ“„ Os PDFs oficiais estÃ£o disponÃ­veis em: [TCE-MG SÃºmulas](https://www.tce.mg.gov.br/Noticia/Detalhe/67)

### 6ï¸âƒ£ IngestÃ£o dos Documentos

Execute o pipeline de ingestÃ£o para processar os PDFs e criar a coleÃ§Ã£o no Qdrant:

```bash
uv run python -m app.ingest.extract_text
```

**O que acontece durante a ingestÃ£o:**
- âœ… ExtraÃ§Ã£o de texto dos PDFs (125 documentos)
- âœ… AnÃ¡lise com GPT-4o-mini para extrair metadados
- âœ… DivisÃ£o em chunks (conteÃºdo, referÃªncias, precedentes)
- âœ… GeraÃ§Ã£o de embeddings (text-embedding-3-large)
- âœ… InserÃ§Ã£o no Qdrant Cloud (~359 chunks)

â±ï¸ **Tempo estimado**: 10-20 minutos (depende da API da OpenAI)

### 7ï¸âƒ£ Executar a AplicaÃ§Ã£o

```bash
uv run streamlit run app.py
```

Acesse: **http://localhost:8501**

---

## ğŸ’¬ Exemplos de Uso

### Consultas BÃ¡sicas

```
"O que diz a sÃºmula 70?"
"Quais sÃºmulas falam sobre licitaÃ§Ã£o?"
"Me explique a sÃºmula 100"
```

### Consultas com Filtros AutomÃ¡ticos

```
"SÃºmulas vigentes sobre contratos administrativos"
â†’ Filtro automÃ¡tico: status_atual = "VIGENTE"

"Quais sÃºmulas foram alteradas em 2014?"
â†’ Filtro automÃ¡tico: data_status_ano = 2014

"Precedentes da sÃºmula 70 vigente"
â†’ Filtros: num_sumula = "70" E status_atual = "VIGENTE"
```

### Consultas Complexas

```
"Compare as sÃºmulas 50 e 60 sobre prestaÃ§Ã£o de contas"
"Quais sÃºmulas revogadas tratavam de servidores pÃºblicos?"
"Me mostre todas as referÃªncias normativas da sÃºmula 85"
```

---

## ğŸ”§ ConfiguraÃ§Ãµes AvanÃ§adas

### Ajustar NÃºmero de Documentos Recuperados

Edite `app/retrieval/retriever.py`:

```python
@dataclass
class SelfQueryConfig:
    collection_name: str = "sumulas_tcemg"
    k: int = 10  # â† Altere aqui (padrÃ£o: 10)
```

### Usar Qdrant Local (Docker)

Se preferir rodar o Qdrant localmente ao invÃ©s do Cloud:

```bash
docker run -d --name qdrant -p 6333:6333 qdrant/qdrant
```

No `.env`, troque para:
```env
QDRANT_URL=http://localhost:6333
QDRANT_API_KEY=  # Deixe vazio para local
```

### Alterar Modelo LLM

Edite `app/ingest/embed_qdrant.py`:

```python
self.llm = ChatOpenAI(
    model="gpt-4o-mini",  # Ou: "gpt-4o", "gpt-4-turbo"
    temperature=0
)
```

---

## ğŸ“Š Observabilidade

### Langfuse Dashboard

Acesse [https://cloud.langfuse.com](https://cloud.langfuse.com) para visualizar:

- ğŸ“ˆ **MÃ©tricas**: Tokens, latÃªncia, custos
- ğŸ” **Traces**: Fluxo completo de cada consulta
- ğŸ’¬ **Prompts**: Templates usados
- ğŸ› **Debug**: Erros e exceptions

### Metadados Rastreados

Cada execuÃ§Ã£o registra:
- `collection`: Nome da coleÃ§Ã£o Qdrant
- `k`: NÃºmero de documentos recuperados
- `tags`: `["rag-tcemg", "sumulas"]`

---

## ğŸ§® Detalhes TÃ©cnicos

### Metadados Estruturados

Cada chunk possui os seguintes metadados:

| Campo | Tipo | Exemplo | DescriÃ§Ã£o |
|-------|------|---------|-----------|
| `num_sumula` | string | "70" | NÃºmero da sÃºmula |
| `status_atual` | string | "VIGENTE" | Status atual |
| `data_status` | string | "07/04/14" | Data formatada |
| `data_status_ano` | integer | 2014 | Ano (para filtros numÃ©ricos) |
| `pdf_name` | string | "SÃºmula 070-89.pdf" | Nome do arquivo |
| `chunk_type` | string | "conteudo_principal" | Tipo do chunk |
| `chunk_index` | integer | 0 | Ãndice do chunk |

### Por Que Armazenar Ano como Inteiro?

O Qdrant sÃ³ suporta comparaÃ§Ãµes (`<`, `>`, `>=`, `<=`) em campos numÃ©ricos. Como as datas originais vÃªm no formato `DD/MM/AA`, nÃ£o Ã© possÃ­vel fazer:

```python
# âŒ NÃ£o funciona (comparaÃ§Ã£o lexicogrÃ¡fica)
"01/01/10" > "31/12/09"  # Retorna False (incorreto!)

# âœ… Funciona (comparaÃ§Ã£o numÃ©rica)
2010 > 2009  # Retorna True
```

Por isso, durante a ingestÃ£o, extraÃ­mos apenas o ano como inteiro no campo `data_status_ano`.

### Tipos de Chunks

Cada sÃºmula Ã© dividida em atÃ© 3 chunks:

1. **conteudo_principal**: Texto vigente da sÃºmula
2. **referencias_normativas**: LegislaÃ§Ã£o relacionada
3. **precedentes**: JurisprudÃªncia e casos anteriores

---

## ğŸ“š ReferÃªncias

### DocumentaÃ§Ã£o Oficial

- [LangChain](https://python.langchain.com/docs/introduction/)
- [LangGraph](https://langchain-ai.github.io/langgraph/)
- [Qdrant](https://qdrant.tech/documentation/)
- [Langfuse](https://langfuse.com/docs)
- [Streamlit](https://docs.streamlit.io/)
- [MarkItDown](https://github.com/microsoft/markitdown)

### APIs Utilizadas

- [OpenAI API](https://platform.openai.com/docs/api-reference)
- [Qdrant REST API](https://qdrant.tech/documentation/interfaces/)

### Artigos e Papers

- [RAG: Retrieval-Augmented Generation](https://arxiv.org/abs/2005.11401)
- [Self-Query Retrieval](https://blog.langchain.dev/query-construction/)

---

## ğŸ¤ Contribuindo

ContribuiÃ§Ãµes sÃ£o bem-vindas! Para contribuir:

1. Fork o projeto
2. Crie uma branch para sua feature (`git checkout -b feature/MinhaFeature`)
3. Commit suas mudanÃ§as (`git commit -m 'Adiciona MinhaFeature'`)
4. Push para a branch (`git push origin feature/MinhaFeature`)
5. Abra um Pull Request

---

## ğŸ“„ LicenÃ§a

Este projeto estÃ¡ sob a licenÃ§a MIT. Veja o arquivo [LICENSE](LICENSE) para mais detalhes.

---

â­ **Se este projeto foi Ãºtil para vocÃª, considere dar uma estrela no [GitHub](https://github.com/mfnogueira/rag-project)!**
