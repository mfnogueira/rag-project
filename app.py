import streamlit as st

from app.graph.rag_graph import run_streaming_rag

# Configura√ß√£o da P√°gina e T√≠tulo
st.set_page_config(
    page_title="Assistente de S√∫mulas TCEMG",
)
st.title("Assistente de S√∫mulas TCEMG")
st.write(
    "Fa√ßa uma pergunta em linguagem natural sobre as s√∫mulas do Tribunal de Contas de Minas Gerais. "
    "O sistema utiliza RAG com Self-Query para inferir filtros automaticamente e realizar busca sem√¢ntica."
)

# Gerenciamento do Hist√≥rico de Chat
if "messages" not in st.session_state:
    st.session_state.messages = []

for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Captura da Pergunta e Execu√ß√£o do Fluxo
if prompt := st.chat_input("Ex: Quais os precedentes da s√∫mula 70 vigente?"):
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Inicia a UI de resposta do assistente
    with st.chat_message("assistant"):
        # Placeholders que ser√£o preenchidos em tempo real
        details_expander = st.expander("üîé **Detalhes da Busca (Self-Query)**")
        query_placeholder = details_expander.empty()
        filter_placeholder = details_expander.empty()
        answer_placeholder = st.empty()

        full_answer = ""

        # Chama a fun√ß√£o do backend e processa os eventos
        # Esta √© a √∫nica intera√ß√£o entre o frontend e o backend!
        for event in run_streaming_rag(prompt):
            if event["type"] == "details":
                data = event["data"]
                query_placeholder.markdown(f"**Busca Sem√¢ntica:** `{data['query']}`")
                filter_placeholder.markdown(
                    f"**Filtro de Metadados:** `{data['filter']}`"
                )

            elif event["type"] == "token":
                token = event["data"]
                full_answer += token
                answer_placeholder.markdown(full_answer + "‚ñå")  # O ‚ñå simula um cursor

            elif event["type"] == "sources":
                answer_placeholder.markdown(full_answer)  # Resposta final sem o cursor
                sources = event["data"]
                if sources:
                    with st.expander("üìö **Fontes Utilizadas**"):
                        for source in sources:
                            st.markdown(
                                f"- **Arquivo:** `{source['pdf_name']}`\n"
                                f"- **S√∫mula:** `{source['num_sumula']}`\n"
                                f"- **Tipo:** `{source['chunk_type']}`"
                            )

    # Adiciona a resposta completa ao hist√≥rico de chat
    st.session_state.messages.append({"role": "assistant", "content": full_answer})
