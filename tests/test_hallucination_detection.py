"""
Testes para o validator de detec√ß√£o de alucina√ß√µes.
"""

import sys
from pathlib import Path

# Adiciona o diret√≥rio raiz do projeto ao PYTHONPATH
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root))

from app.guardrails.guards import HallucinationDetection


def test_valid_response_with_context():
    """Testa resposta v√°lida baseada no contexto."""
    print("\n" + "=" * 60)
    print("TESTE 1: Resposta v√°lida com base no contexto")
    print("=" * 60)

    validator = HallucinationDetection(threshold=0.7)

    response = """
    A S√∫mula 70 do TCEMG estabelece crit√©rios para contratos administrativos.
    Conforme a S√∫mula 112, os procedimentos licitat√≥rios devem seguir
    as normas estabelecidas pela legisla√ß√£o vigente.
    """

    metadata = {
        "retrieved_sumulas": ["70", "112"],
        "context_text": """
        S√∫mula 70: Contratos administrativos devem seguir crit√©rios espec√≠ficos.
        S√∫mula 112: Procedimentos licitat√≥rios conforme legisla√ß√£o vigente.
        """
    }

    result = validator.validate(response, metadata)

    print(f"Resposta: {response[:100]}...")
    print(f"\nResultado: {result.outcome}")
    print(f"S√∫mulas citadas: {result.metadata.get('cited_sumulas')}")
    print(f"S√∫mulas recuperadas: {result.metadata.get('retrieved_sumulas')}")
    print(f"Score de alucina√ß√£o: {result.metadata.get('hallucination_score')}")
    print(f"Issues: {result.metadata.get('issues')}")

    assert result.outcome == "pass", "Resposta v√°lida deveria passar"
    print("\n‚úÖ TESTE PASSOU")


def test_hallucinated_sumula():
    """Testa resposta que cita s√∫mula n√£o recuperada."""
    print("\n" + "=" * 60)
    print("TESTE 2: Alucina√ß√£o - S√∫mula n√£o recuperada")
    print("=" * 60)

    validator = HallucinationDetection(threshold=0.7)

    response = """
    A S√∫mula 70 estabelece crit√©rios para contratos.
    Al√©m disso, a S√∫mula 999 determina procedimentos especiais
    que devem ser seguidos em casos excepcionais.
    """

    metadata = {
        "retrieved_sumulas": ["70"],  # S√≥ recuperou 70, n√£o 999
        "context_text": "S√∫mula 70: Contratos administrativos..."
    }

    result = validator.validate(response, metadata)

    print(f"Resposta: {response[:100]}...")
    print(f"\nResultado: {result.outcome}")
    print(f"S√∫mulas citadas: {result.metadata.get('cited_sumulas')}")
    print(f"S√∫mulas recuperadas: {result.metadata.get('retrieved_sumulas')}")
    print(f"Score de alucina√ß√£o: {result.metadata.get('hallucination_score')}")
    print(f"Issues: {result.metadata.get('issues')}")

    assert result.outcome == "fail", "Deve detectar s√∫mula n√£o recuperada"
    assert "999" in str(result.metadata.get('issues')), "Deve mencionar s√∫mula 999"
    print("\n‚úÖ TESTE PASSOU - Alucina√ß√£o detectada corretamente")


def test_no_grounding_in_context():
    """Testa resposta sem base no contexto."""
    print("\n" + "=" * 60)
    print("TESTE 3: Resposta sem base no contexto")
    print("=" * 60)

    validator = HallucinationDetection(threshold=0.7)

    response = """
    A legisla√ß√£o ambiental brasileira estabelece normas rigorosas
    para prote√ß√£o de florestas tropicais e conserva√ß√£o de
    esp√©cies em extin√ß√£o conforme tratados internacionais.
    """

    metadata = {
        "retrieved_sumulas": ["70"],
        "context_text": "S√∫mula 70: Contratos administrativos devem seguir crit√©rios..."
    }

    result = validator.validate(response, metadata)

    print(f"Resposta: {response[:100]}...")
    print(f"\nResultado: {result.outcome}")
    print(f"Score de alucina√ß√£o: {result.metadata.get('hallucination_score')}")
    print(f"Issues: {result.metadata.get('issues')}")

    # Esperamos que falhe por falta de grounding
    if result.outcome == "fail":
        print("\n‚úÖ TESTE PASSOU - Falta de grounding detectada")
    else:
        print("\n‚ö†Ô∏è  AVISO: Resposta passou mas deveria ter falhado")


def test_excessive_assertions():
    """Testa resposta com muitas afirma√ß√µes categ√≥ricas."""
    print("\n" + "=" * 60)
    print("TESTE 4: Muitas afirma√ß√µes categ√≥ricas sem incerteza")
    print("=" * 60)

    validator = HallucinationDetection(threshold=0.7)

    response = """
    A S√∫mula 70 estabelece que todos os contratos devem ser anuais.
    Conforme a S√∫mula 70, √© obrigat√≥rio seguir o procedimento X.
    A S√∫mula determina que pagamentos sejam mensais.
    Segundo a S√∫mula 70, multas s√£o aplic√°veis em todos os casos.
    """

    metadata = {
        "retrieved_sumulas": ["70"],
        "context_text": "S√∫mula 70: Contratos administrativos..."
    }

    result = validator.validate(response, metadata)

    print(f"Resposta: {response[:100]}...")
    print(f"\nResultado: {result.outcome}")
    print(f"Afirma√ß√µes categ√≥ricas: {result.metadata.get('assertive_count')}")
    print(f"Marcadores de incerteza: {result.metadata.get('uncertainty_count')}")
    print(f"Score de alucina√ß√£o: {result.metadata.get('hallucination_score')}")

    print(f"\n{'‚úÖ' if result.metadata.get('assertive_count', 0) > 0 else '‚ùå'} Detectou afirma√ß√µes categ√≥ricas")


def test_with_uncertainty_markers():
    """Testa resposta com marcadores de incerteza (BOA)."""
    print("\n" + "=" * 60)
    print("TESTE 5: Resposta com marcadores de incerteza")
    print("=" * 60)

    validator = HallucinationDetection(threshold=0.7)

    response = """
    Segundo os documentos recuperados, a S√∫mula 70 aparentemente
    estabelece crit√©rios para contratos. Baseado no contexto,
    possivelmente h√° requisitos espec√≠ficos que devem ser seguidos.
    """

    metadata = {
        "retrieved_sumulas": ["70"],
        "context_text": "S√∫mula 70: Contratos administrativos devem seguir crit√©rios..."
    }

    result = validator.validate(response, metadata)

    print(f"Resposta: {response[:100]}...")
    print(f"\nResultado: {result.outcome}")
    print(f"Marcadores de incerteza: {result.metadata.get('uncertainty_count')}")
    print(f"Score de alucina√ß√£o: {result.metadata.get('hallucination_score')}")

    assert result.outcome == "pass", "Resposta com marcadores de incerteza deveria passar"
    print("\n‚úÖ TESTE PASSOU - Marcadores de incerteza ajudaram")


def run_all_tests():
    """Executa todos os testes."""
    print("\n" + "=" * 60)
    print("üß™ TESTES DE DETEC√á√ÉO DE ALUCINA√á√ïES")
    print("=" * 60)

    try:
        test_valid_response_with_context()
        test_hallucinated_sumula()
        test_no_grounding_in_context()
        test_excessive_assertions()
        test_with_uncertainty_markers()

        print("\n" + "=" * 60)
        print("‚úÖ TODOS OS TESTES CONCLU√çDOS")
        print("=" * 60)
        return True

    except AssertionError as e:
        print(f"\n‚ùå TESTE FALHOU: {e}")
        return False
    except Exception as e:
        print(f"\n‚ùå ERRO INESPERADO: {e}")
        import traceback
        traceback.print_exc()
        return False


if __name__ == "__main__":
    success = run_all_tests()
    exit(0 if success else 1)
